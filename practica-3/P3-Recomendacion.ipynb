{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2023 Pablo Castells y Alejandro Bellogín\n",
    "\n",
    "El código que contiene este notebook se ha implementado para la realización de las prácticas de la asignatura \"Búsqueda y minería de información\" de 4º del Grado en Ingeniería Informática, impartido en la Escuela Politécnica Superior de la Universidad Autónoma de Madrid. El fin del mismo, así como su uso, se ciñe a las actividades docentes de dicha asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKBXprvhpqQr"
   },
   "source": [
    "### **Búsqueda y Minería de Información 2022-23**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Grado en Ingeniería Informática, 4º curso\n",
    "\n",
    "# Bloque 1 &ndash; Sistemas de recomendación\n",
    "\n",
    "Fechas:\n",
    "\n",
    "* Comienzo: martes 28 / jueves 30 de marzo\n",
    "* Entrega: lunes 8 de mayo, 23:59\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Este primer bloque de la práctica tiene por objetivo la implementación y evaluación eficiente de sistemas de recomendación. En este bloque se desarrollarán:\n",
    "\n",
    "* Estructuras para el manejo de datos de interacción entre usuarios e items (\"ratings\" para simplificar).\n",
    "* Algoritmos de recomendación basada en filtrado colaborativo.\n",
    "* Métricas de evaluación de sistemas de recomendación.\n",
    "\n",
    "## Material proporcionado\n",
    "\n",
    "Se proporcionan software y datos para la realización de la práctica:\n",
    "\n",
    "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. \n",
    "  - De modo similar a las prácticas anteriores, se proporciona una celda de prueba al final de este notebook que deberá funcionar con las implementaciones del estudiante.\n",
    "  - Junto a la celda de prueba en este mismo notebook, se muestra como referencia un ejemplo de salida generada con una implementación de los profesores.\n",
    "* Los siguientes conjuntos de datos de ratings por usuarios a items:\n",
    "  - Dos conjuntos de juguete para prueba y depuración: <ins>toy1.csv</ins> (se genera en Matrices.ipynb) y <ins>toy2.csv</ins> (proporcionado en el curso Moodle) con ratings ficticios.\n",
    "  - Un conjunto de datos reales de ratings a películas: *ml-1m.zip* disponible en la Web de [MovieLens](https://grouplens.org/datasets/movielens/1m). De los archivos disponibles, se utilizará sólamente <ins>ratings.dat</ins>, añadiéndole una cabecera `u::i::r::t`.\n",
    "  \n",
    "Los esqueletos de código que se proporcionan aquí son a modo de guía: el estudiante puede modificarlo todo libremente, siempre que la celda de prueba funcione correctamente **sin cambios**.\n",
    "\n",
    "## Calificación\n",
    "\n",
    "El peso de esta práctica (recomendación + redes sociales) en la nota final de prácticas es del **40%**.\n",
    "\n",
    "La calificación se basará en el **número** de ejercicios realizados y la **calidad** de los mismos. La puntuación que se indica en cada apartado es orientativa, en principio se aplicará tal cual se refleja pero podrá matizarse por criterios de buen sentido si se da el caso.\n",
    "\n",
    "Para dar por válida la realización de un ejercicio, el código deberá funcionar (a la primera) integrado con las clases que se facilitan. El profesor comprobará este aspecto ejecutando la celda de prueba y otras adicionales.\n",
    "\n",
    "La corrección de las implementaciones se observará por la **coherencia de los resultados** (por ejemplo, las métricas sobre los algoritmos de recomendación), y se valorará la eficiencia en tiempo de ejecución.\n",
    "\n",
    "## Entrega\n",
    "\n",
    "La entrega consistirá en dos ficheros tipo *notebook* (uno para recomendación y otro para redes sociales) donde se incluirán todas las **implementaciones** solicitadas en cada ejercicio, así como una explicación de cada uno a modo de **memoria**.\n",
    "\n",
    "## Indicaciones\n",
    "\n",
    "La realización de los ejercicios conducirá en muchos casos a la implementación de funciones y/o clases adicionales a las que se indican en el enunciado. Algunas vendrán dadas por su aparición en los propias celdas de prueba, y otras por conveniencia a criterio del estudiante.\n",
    "\n",
    "Igual que en prácticas anteriores, no deberán editarse las celdas de prueba. Estas celdas deberán ejecutar sin errores a la primera con el código entregado por el estudiante (naturalmente con salvedad de los ejercicios que no se hayan implementado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores\n",
    "\n",
    "Xu Chen Xu <br>\n",
    "Ana Martínez Sabiote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ejercicio 1: Estructuras de datos y recomendación simple (2pt)\n",
    "\n",
    "#### 1.1 &nbsp; Estructuras de datos\n",
    "\n",
    "Implementar las clases necesarias para manejar **datos de entrada y prueba** (ratings) para los algoritmos de recomendación. La funcionalidad se implementará en una clase Ratings, que permitirá leer los datos de un fichero de texto, así como un método que genere dos particiones aleatorias de entrenamiento y test, para evaluar y comparar la efectividad de diferentes algoritmos de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Ratings:\n",
    "    def __init__(self, file=None, sep=',', df=None):\n",
    "        # Código aquí...\n",
    "        if file is not None:\n",
    "            self.ratings_df=pd.read_csv(filepath_or_buffer=file, sep = sep)\n",
    "        elif df is not None:\n",
    "            self.ratings_df=df\n",
    "        else:\n",
    "            raise Exception(\"No se ha especificado un fichero ni un dataframe\")\n",
    "\n",
    "        self.uids=self.ratings_df.u.unique()\n",
    "        self.iids=self.ratings_df.i.unique()\n",
    "        matrix = self.ratings_df.pivot(index='u', columns='i', values='r')\n",
    "        matrix = matrix.fillna(0)\n",
    "        self.m = matrix.to_numpy()\n",
    "\n",
    "        self.uidx_to_uid_dict = np.sort(self.ratings_df.u.unique())\n",
    "        self.iidx_to_iid_dict = np.sort(self.ratings_df.i.unique())\n",
    "        self.uid_to_uidx_dict = {u:j for j, u in enumerate(self.uidx_to_uid_dict)}\n",
    "        self.iid_to_iidx_dict = {i:j for j, i in enumerate(self.iidx_to_iid_dict)}\n",
    "\n",
    "    def matrix(self):\n",
    "        # Código aquí...\n",
    "        return self.m\n",
    "\n",
    "    def nusers(self):\n",
    "        return self.m.shape[0]\n",
    "\n",
    "    def nitems(self):\n",
    "        # Código aquí...\n",
    "        return self.m.shape[1]\n",
    "\n",
    "    # uidx can be an int or an array-like of ints.\n",
    "    def uidx_to_uid(self, uidx):\n",
    "        # Código aquí...\n",
    "        return self.uidx_to_uid_dict[uidx]\n",
    "\n",
    "    # iidx can be an int or an array-like of ints.\n",
    "    def iidx_to_iid(self, iidx):\n",
    "        # Código aquí...\n",
    "        return self.iidx_to_iid_dict[iidx]\n",
    "\n",
    "    # uid can be an int or an array-like of ints.\n",
    "    def uid_to_uidx(self, uid):\n",
    "        # Código aquí...\n",
    "        return self.uid_to_uidx_dict[uid]\n",
    "\n",
    "    # iid can be an int or an array-like of ints.\n",
    "    def iid_to_iidx(self, iid):\n",
    "        # Código aquí...\n",
    "        return self.iid_to_iidx_dict[iid]\n",
    "\n",
    "    def iidx_rated_by(self, uidx):\n",
    "        # Código aquí...\n",
    "        # Distintos de cero por filas\n",
    "        positions = np.where(self.m[uidx,:]!=0)\n",
    "        return positions\n",
    "\n",
    "    def uidx_who_rated(self, iidx):\n",
    "        # Código aquí...\n",
    "        # Distintos de cero por columnas\n",
    "        positions = np.where(self.m[:,iidx]!=0)\n",
    "        return positions\n",
    "\n",
    "\n",
    "    def random_split(self, ratio):\n",
    "        # Código aquí...\n",
    "        # Devuelve dos objetos ratings\n",
    "        # Usar pandas.DataFrame.Sample sobre self.ratings_df para obtener los dataframes \n",
    "        # train y test y crear un objeto Ratings a partir de esos dataframes. \n",
    "\n",
    "        # Dividimos el dataframe en dos partes\n",
    "        mask_1 = np.random.choice([1,0], size=self.matrix().shape, p=[ratio,1-ratio])\n",
    "        training = self.matrix()*mask_1\n",
    "\n",
    "        mask_2 = 1-mask_1\n",
    "        test = self.matrix()*mask_2\n",
    "\n",
    "        df1=pd.DataFrame(training, index=self.uidx_to_uid_dict, columns=self.iidx_to_iid_dict)\n",
    "        df2=pd.DataFrame(test, index=self.uidx_to_uid_dict, columns=self.iidx_to_iid_dict) \n",
    "        df1=df1.unstack().reset_index(name='r')\n",
    "        df1.columns = ['i', 'u', 'r']\n",
    "        df2=df2.unstack().reset_index(name='r')\n",
    "        df2.columns = ['i', 'u', 'r']\n",
    "\n",
    "\n",
    "        #df1 = self.ratings_df.sample(frac=ratio)\n",
    "        # CORREGIR df2: ES NECESARIO  QUE df1 Y df2 TENGAN LA MISMA DIMENSIÓN\n",
    "        #df2 = self.ratings_df.loc[~self.ratings_df.index.isin(df1.index)]\n",
    "\n",
    "\n",
    "        # Creamos los objetos Ratings\n",
    "        ratings1 = Ratings(df=df1)\n",
    "        ratings2 = Ratings(df=df2)\n",
    "\n",
    "        return ratings1, ratings2\n",
    "\n",
    "    #\n",
    "    # The remaining functions are just for debugging purposes\n",
    "    #\n",
    "\n",
    "    def rating(self, uid, iid):\n",
    "        # Código aquí...\n",
    "        uidx=self.uid_to_uidx(uid)\n",
    "        iidx=self.iid_to_iidx(iid)\n",
    "        return self.m[uidx,iidx]\n",
    "\n",
    "    def items_rated_by(self, uid):\n",
    "        # Código aquí...2\n",
    "        uidx=self.uid_to_uidx(uid)\n",
    "        return self.iidx_to_iid(self.iidx_rated_by(uidx))\n",
    "\n",
    "    def users_who_rated(self, iid):\n",
    "        # Código aquí...\n",
    "        iidx=self.iid_to_iidx(iid)\n",
    "        return self.uidx_to_uid(self.uidx_who_rated(iidx))\n",
    "\n",
    "    def user_ratings(self, uid):\n",
    "        # Código aquí...\n",
    "        uidx=self.uid_to_uidx(uid)\n",
    "        positions=np.where(self.m[uidx,:]!=0)\n",
    "        ratings=self.m[uidx, positions]\n",
    "        return dict(zip(self.items_rated_by(uid),ratings[0,:]))\n",
    "\n",
    "    def item_ratings(self, iid):\n",
    "        # Código aquí...\n",
    "        iidx=self.iid_to_iidx(iid)\n",
    "        positions=np.where(self.m[:,iidx]!=0)\n",
    "        ratings=self.m[positions,iidx]\n",
    "        return dict(zip(self.users_who_rated(iid),np.concatenate(ratings)))\n",
    "        \n",
    "\n",
    "    def nratings(self):\n",
    "        # Código aquí...\n",
    "        return np.count_nonzero(self.m)\n",
    "\n",
    "    # To inspect random data splits.\n",
    "    def save(self, file):\n",
    "        df = pd.DataFrame(columns=self.iids, index=self.uids, data=self.m).unstack().reset_index(name='r')\n",
    "        df.columns = ['i', 'u', 'r']\n",
    "        df = df[df.r>0][['u', 'i', 'r']].sort_values(by=['u', 'i'])\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "# Just for pretty-printing numbers.\n",
    "def fround(x, n=20):\n",
    "    r = round(x)\n",
    "    rn = round(x, n)\n",
    "    return r if rn == r else rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# example array\n",
    "a = np.array([[1, 0, 0], [0, 0, 6]])\n",
    "\n",
    "# a to one dimension\n",
    "a = a.flatten()\n",
    "\n",
    "# get the indexes of the non-zero values\n",
    "idx = np.nonzero(a)\n",
    "\n",
    "# Select 0.8 proportions of the indexes\n",
    "idx_1 = np.random.choice(idx[0], size=int(0.8*len(idx[0])), replace=False)\n",
    "\n",
    "# Create a mask of zeros and ones\n",
    "mask = np.zeros(len(a))\n",
    "mask[idx_1] = 1\n",
    "\n",
    "# Apply the mask to the array\n",
    "a = a*mask\n",
    "\n",
    "# Reshape the array to the original shape\n",
    "a = a.reshape(2,3)\n",
    "\n",
    "# Print the array\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 5., 3., 0.],\n",
       "       [5., 2., 0., 0., 4.],\n",
       "       [1., 4., 4., 0., 0.],\n",
       "       [0., 0., 3., 5., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = Ratings('recsys-data/toy1.csv')\n",
    "\n",
    "m = ratings.matrix()\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False,  True, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False, False, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = Ratings('recsys-data/toy1.csv')\n",
    "\n",
    "proportion = 0.8\n",
    "m = ratings.matrix()\n",
    "\n",
    "# Create matrix with same size as m but filled with zeros\n",
    "m_zeros = np.zeros(m.shape)\n",
    "\n",
    "# In the positions where m > 0, put a random number\n",
    "m_zeros[m>0] = np.random.rand(np.count_nonzero(m))\n",
    "\n",
    "m_zeros > proportion\n",
    "# train, test = ratings.random_split(0.8)\n",
    "\n",
    "# display(pd.DataFrame(ratings.matrix(), index=ratings.uidx_to_uid_dict, columns=ratings.iidx_to_iid_dict))\n",
    "# display(pd.DataFrame(train.matrix(), index=train.uidx_to_uid_dict, columns=train.iidx_to_iid_dict))\n",
    "# display(pd.DataFrame(test.matrix(), index=test.uidx_to_uid_dict, columns=test.iidx_to_iid_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 &nbsp;  Recomendaciones: métodos simples no personalizados\n",
    "\n",
    "La **salida** de un recomendador consistirá en un diccionario con un ránking por usuario. \n",
    "\n",
    "Implementar un primer **recomendador simple** por rating promedio en una clase `AverageRecommender`. El recomendador sólo recomendará items que tengan un mínimo número de ratings, que se indicará como parámetro en el constructor (con ello se mejora el acierto de la recomendación). Se proporciona una clase `MajorityRecommender` a modo de ejemplo en el que el estudiante podrá basarse, así como `RandomRecommender`, que se utiliza en ocasiones como referencia en experimentos. \n",
    "\n",
    "**Importante**: recordar que no deben recomendarse los items que los usuarios ya hayan puntuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3 2]\n",
      " [4 3 2]\n",
      " [4 3 2]]\n",
      "[[1 3]\n",
      " [3 5]]\n",
      "[[1 5]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplos míos para entender las funciones de la celda siguiente.\n",
    "\n",
    "def top_positions_per_row(m, k):\n",
    "    return np.sort(np.argpartition(m, -k)[:, -k:], axis=1)[:, ::-1]\n",
    "\n",
    "def get_elements(m, indices, cutoff=np.inf):\n",
    "    return np.array([s[t[0:min(cutoff, len(t))]] for s, t in zip(m, indices)])\n",
    "\n",
    "matrix = np.array([[1, 2, 3, 4, 5],[3,4,5,6,7], [5,6,7,8,9]])\n",
    "\n",
    "print(top_positions_per_row(matrix, 3))\n",
    "\n",
    "print(get_elements(matrix, [[0,2],[0,2]]))\n",
    "\n",
    "aux = np.array([[0,4],[0,2]])\n",
    "\n",
    "print(get_elements(matrix, aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suggestion: compute the scores in the recommenders' constructor.\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "# Given a matrix, returns a matrix of positions of top k values per row.\n",
    "def top_positions_per_row(m, k):\n",
    "    return np.sort(np.argpartition(m, -k)[:, -k:], axis=1)[:, ::-1]\n",
    "\n",
    "# Given a matrix and a set of indices per rows, returns the matrix values for the indices. \n",
    "# This function is used in the Recommender class and metrics classes.\n",
    "def get_elements(m, indices, cutoff=np.inf):\n",
    "    return np.array([s[t[0:min(cutoff, len(t))]] for s, t in zip(m, indices)])\n",
    "\n",
    "class Recommendation:\n",
    "    def __init__(self, scores, n, training):\n",
    "        # Código aquí...\n",
    "        # Indicación: generar aquí los ránkings de scores, de iidx's y de iids.\n",
    "        self.scores = scores\n",
    "\n",
    "        self.top_iidx = top_positions_per_row(scores, n)\n",
    "        # Sort because top_positions_per_row returns the top unsorted.\n",
    "        self.ranked_iidx = get_elements(self.top_iidx, np.argsort(get_elements(scores, self.top_iidx))[:, ::-1])\n",
    "\n",
    "        # And now get the ranked uids and scores.\n",
    "        ranked_iids = training.iidx_to_iid(self.ranked_iidx)\n",
    "        rank_scores = get_elements(scores, self.ranked_iidx)\n",
    "\n",
    "        self._recommendation = {uid : [(iid, score) for iid, score in zip(ranked_iids[uidx], rank_scores[uidx]) if score > 0]\n",
    "                for uidx, uid in enumerate(training.uidx_to_uid_dict)}\n",
    "\n",
    "    def ranked_iidx(self):\n",
    "        # Código aquí...\n",
    "        return self.ranked_iidx\n",
    "\n",
    "    def recommendation(self, uid):\n",
    "        # Código aquí...\n",
    "        return self._recommendation[uid]\n",
    "\n",
    "    # Format the recommendation as a string for the first n users. Trim scores to 4 decimal digits.\n",
    "    def display(self, n):\n",
    "        r = ''\n",
    "        for uid in islice(self._recommendation, n):\n",
    "            r += f'    User {uid} -> <' \n",
    "            for iid, score in self.recommendation(uid): \n",
    "                r += f'{iid}:' + str(fround(score, 4)) + ' '\n",
    "            r = (r[:-1] + '>\\n') if len(self.recommendation(uid)) > 0 else r + 'empty>\\n'\n",
    "        return r[:-1]\n",
    "\n",
    "class Recommender():\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__\n",
    "\n",
    "    def recommend(self, n):\n",
    "        return Recommendation(self.scores, n, self.training)\n",
    "\n",
    "class RandomRecommender(Recommender):\n",
    "    def __init__(self, training):\n",
    "        super().__init__(training)\n",
    "        self.scores = np.random.random(training.matrix().shape)\n",
    "\n",
    "class MajorityRecommender(Recommender):\n",
    "    def __init__(self, training, threshold=0):\n",
    "        super().__init__(training)\n",
    "        # training.matrix() >= threshold creates a mask with 'True' on relevant ratings and 'False' anywhere\n",
    "        # else. Thus 'pop' is an array with the counts of relevant ratings of each item.\n",
    "\n",
    "        pop = np.sum(training.matrix() >= threshold, axis=0)\n",
    "\n",
    "        # This product by a vector of ones (of user-row length) creates a matrix where the pop vector gets\n",
    "        # copied on all rows; the recommendation is not personalized and ranking is the same for all users \n",
    "        # -- except of course in the end different training items will be filtered out for different users.\n",
    "        self.scores = np.outer(np.ones(training.nusers()), pop)\n",
    "\n",
    "class AverageRecommender(Recommender):\n",
    "    def __init__(self, training, minr=0):\n",
    "        super().__init__(training)\n",
    "        self.minr = minr\n",
    "\n",
    "        not_rated_mask = (training.matrix() == 0)\n",
    "\n",
    "        # Calculamos la suma de los ratings para cada item\n",
    "        sum_ratings = training.matrix().sum(axis=0)\n",
    "\n",
    "        # Calculamos el número de ratings de cada item\n",
    "        n_ratings = (training.matrix() > 0).sum(axis=0)\n",
    "\n",
    "        mean_ratings = np.divide(sum_ratings, n_ratings, \n",
    "                                 out=np.zeros_like(sum_ratings), where = (n_ratings!=0))\n",
    "\n",
    "        # Creamos un vector con la media de los ratings de cada item\n",
    "        # si tiene por lo menos minr ratings. Si tiene menos, la media es 0.\n",
    "        mean_ratings = np.where(n_ratings >= minr, mean_ratings, 0)\n",
    "\n",
    "        # Creamos la matriz de scores donde cada score es la media de los ratings\n",
    "        self.scores = np.outer(np.ones(training.nusers()), mean_ratings)\n",
    "\n",
    "        # Nos quedamos solo con los scores de los items que no han sido valorados por cada usuario\n",
    "        self.scores = self.scores * not_rated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d    e\n",
       "v  0.0  4.0  5.0  3.0  0.0\n",
       "x  5.0  2.0  0.0  0.0  4.0\n",
       "y  1.0  4.0  4.0  0.0  0.0\n",
       "z  0.0  0.0  3.0  5.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a         b    c    d    e\n",
       "v  3.0  0.000000  0.0  0.0  0.0\n",
       "x  0.0  0.000000  4.0  4.0  0.0\n",
       "y  0.0  0.000000  0.0  4.0  0.0\n",
       "z  3.0  3.333333  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda de testing\n",
    "ratings = Ratings('recsys-data/toy1.csv', sep=',')\n",
    "\n",
    "ratings.matrix()\n",
    "\n",
    "# Create df from np array\n",
    "display(pd.DataFrame(ratings.matrix(), index=ratings.uidx_to_uid_dict, columns=ratings.iidx_to_iid_dict))\n",
    "\n",
    "# Create AverageRecommender\n",
    "mr = AverageRecommender(ratings, 2)\n",
    "\n",
    "display(pd.DataFrame(mr.scores, index=ratings.uidx_to_uid_dict, columns=ratings.iidx_to_iid_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2], dtype=int64),)\n",
      "[[2 3 4]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[2,3,4],[2,0,4],[3,3,3],[0,0,1]])\n",
    "resultado=np.where(a[1,:]!=0)\n",
    "print(resultado)\n",
    "print(a[resultado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 2],\n",
       "       [1, 2, 3],\n",
       "       [4, 2, 0],\n",
       "       [1, 0, 3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'v': [('a', 0.9858277478168467),\n",
       "  ('d', 0.9374213594623059),\n",
       "  ('c', 0.7627218681945643)],\n",
       " 'x': [('b', 0.9369089199558277),\n",
       "  ('c', 0.7257347699656793),\n",
       "  ('d', 0.5937670613617214)],\n",
       " 'y': [('e', 0.859549759257613),\n",
       "  ('c', 0.5581464914135078),\n",
       "  ('a', 0.4788612704595886)],\n",
       " 'z': [('b', 0.8464838392835399),\n",
       "  ('a', 0.5745280037011418),\n",
       "  ('d', 0.3294377427883902)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User v -> <a:0.9858 d:0.9374 c:0.7627>\n",
      "    User x -> <b:0.9369 c:0.7257 d:0.5938>\n",
      "    User y -> <e:0.8595 c:0.5581 a:0.4789>\n"
     ]
    }
   ],
   "source": [
    "# Celda de testing\n",
    "ratings = Ratings('recsys-data/toy1.csv', sep=',')\n",
    "\n",
    "rec = RandomRecommender(ratings)\n",
    "rec = rec.recommend(3)\n",
    "display(rec.ranked_iidx)\n",
    "display(rec._recommendation)\n",
    "print(rec.display(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 4. 5. 3. 0.]\n",
      " [5. 2. 0. 0. 4.]\n",
      " [1. 4. 4. 0. 0.]\n",
      " [0. 0. 3. 5. 0.]]\n",
      "[[0. 4. 0. 3. 0.]\n",
      " [5. 2. 0. 0. 4.]\n",
      " [0. 4. 0. 0. 0.]\n",
      " [0. 0. 3. 5. 0.]]\n",
      "[[0. 0. 5. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "training,test=ratings.random_split(0.8)\n",
    "print(ratings.matrix())\n",
    "print(training.matrix())\n",
    "print(test.matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3YGEGm7haop",
    "tags": []
   },
   "source": [
    "### Ejercicio 1 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ti8qGedgNB",
    "tags": []
   },
   "source": [
    "## Ejercicio 2: Filtrado colaborativo kNN (2pt)\n",
    "\n",
    "Implementar un algoritmo de filtrado colaborativo mediante vecinos próximos orientado a usuarios por *similitud coseno* (sin normalizar por la suma de similitudes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wzZ-6OG0dvwX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineUserSimilarity:\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "        ratings_matrix = training.matrix()\n",
    "\n",
    "        dots = ratings_matrix @ ratings_matrix.T\n",
    "        mods = np.sqrt(dots.diagonal())\n",
    "\n",
    "        # To avoid 0/0 later if some row is all zeros (and hence the row modulus is zero).\n",
    "        mods[mods==0] = 1\n",
    "\n",
    "        # Vamos ahora a dividir por los modulos\n",
    "        # Dividimos cada fila de dots por cada elemento de mods\n",
    "        # Es decir, primera fila de mods por primer elemento de mods,...\n",
    "        self.sim = dots/mods[:, None]\n",
    "\n",
    "        # Dividimos cada columna de sim por cada elemento de mods.\n",
    "        # Es decir, primera columna de sim por primer elemento de mods,...\n",
    "        self.sim = self.sim/mods\n",
    "\n",
    "        # Ponemos a 0 la diagonal porque no queremos que un usuario sea similar a si mismo\n",
    "        np.fill_diagonal(self.sim,0)\n",
    "\n",
    "    def similarity_matrix(self):\n",
    "        return self.sim\n",
    "\n",
    "class UserKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k):\n",
    "        super().__init__(training)\n",
    "        self.sim = sim\n",
    "        self.k = k\n",
    "\n",
    "        not_rated_mask = (training.matrix() == 0)\n",
    "\n",
    "        # Indices de los k usuarios mas similares a cada usuario\n",
    "        uidx = top_positions_per_row(sim.similarity_matrix(), k)\n",
    "\n",
    "        # Mascara con 1s en las posiciones de los k usuarios mas similares a cada usuario\n",
    "        # y 0s en el resto\n",
    "        top_similar_mask = np.zeros_like(sim.similarity_matrix())\n",
    "        top_similar_mask[np.arange(top_similar_mask.shape[0]), uidx.T] = 1\n",
    "\n",
    "        # Matriz de similitudes entre los k usuarios mas similares a cada usuario.\n",
    "        # El resto es 0.\n",
    "        knn_sim = sim.similarity_matrix() * top_similar_mask\n",
    "\n",
    "        # Creamos la matriz de scores donde cada score es la media ponderada (segun la similitud entre usuarios)\n",
    "        # de los ratings de los k usuarios mas similares\n",
    "        self.scores = knn_sim @ training.matrix()\n",
    "\n",
    "        # Nos quedamos solo con los scores de los items que no han sido valorados por cada usuario\n",
    "        self.scores = self.scores * not_rated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': [('a', 0.8862587350511957)],\n",
       " 'x': [('c', 2.1926722125915408), ('d', 0.5059644256269407)],\n",
       " 'y': [('d', 4.450020507233184)],\n",
       " 'z': [('b', 4.343422942099672), ('a', 0.35824886041591925)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('c', 2.1926722125915408), ('d', 0.5059644256269407)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda de testing (aún no he mirado que este bien)\n",
    "# Ana: confirmo que comparándolo con el ejemplo de P3-Matrices.ipynb SÍ funciona correctamente\n",
    "rec = UserKNNRecommender(ratings, CosineUserSimilarity(ratings), 2)\n",
    "recommendation = rec.recommend(3)\n",
    "\n",
    "display(recommendation._recommendation)\n",
    "\n",
    "recommendation.recommendation('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88625874 0.         0.         0.         0.        ]\n",
      " [0.         0.         2.19267221 0.50596443 0.        ]\n",
      " [0.         0.         0.         4.45002051 0.        ]\n",
      " [0.35824886 4.34342294 0.         0.         0.        ]]\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         4.45002051 0.        ]\n",
      " [0.         4.34342294 0.         0.         0.        ]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anama\\AppData\\Local\\Temp/ipykernel_17080/1229805489.py:13: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  pk.append(np.sum(scores[:,i])/i)\n"
     ]
    }
   ],
   "source": [
    "print(recommendation.scores)\n",
    "mask_cutoff=(recommendation.scores>4.0)\n",
    "\n",
    "mask_test=(test==0)\n",
    "scores=recommendation.scores*mask_cutoff\n",
    "print(scores)\n",
    "scores=(scores>0).astype(int)\n",
    "print(scores)\n",
    "pk=[]\n",
    "scores=(scores>0).astype(int)\n",
    "# Vamos sumando las filas y dividiendo por k\n",
    "for i in range(scores.shape[1]):\n",
    "    pk.append(np.sum(scores[:,i])/i)\n",
    "# Sumamos por columnas y dividimos por el número de filas, es decir, de usuarios    \n",
    "result=np.sum(pk,axis=0)/scores.shape[1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVzsIg0Zev7a",
    "tags": []
   },
   "source": [
    "## Ejercicio 3: Evaluación (1pt)\n",
    "\n",
    "Se desarrollarán clases que permitan calcular métricas para evaluar y comparar el acierto de los recomendadores: se implementarán **precisión** y **recall**. \n",
    "\n",
    "Como resumen de este bloque, se incluirá una *tabla con los valores de las métricas* (dos columnas) más el tiempo de ejecución (una columna más) sobre todos los algoritmos implementados (filas), al menos para el conjunto de datos de <ins>MovieLens 1M</ins>. En el caso de ser capaces de procesar un conjunto de datos más grande, se documentará el tamaño en RAM de la matriz de ratings.\n",
    "\n",
    "<!-- Opcionalmente, se podrán implementar otras métricas a elección del estudiante (nDCG, etc.), cuya prueba se incluirá en la función `student_test()` del ejercicio 4 (\"ampliaciones\"). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VqSKneeSe2bN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self, test, cutoff):\n",
    "        # Objeto raitings que contiene la partición de test\n",
    "        self.test = test\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + ('@' + str(self.cutoff) if self.cutoff != np.inf else '')\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(test, cutoff)\n",
    "        # Código aquí...\n",
    "        # threshold debe ser el umbral de relevancia\n",
    "        self.threshold=threshold\n",
    "    \n",
    "        \n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        # Código aquí...  \n",
    "        # Nos quedamos con los relevantes\n",
    "        # COGER TOP cutoff\n",
    "        top_iidx = top_positions_per_row(recommendation.scores, self.cutoff)\n",
    "        # Sort because top_positions_per_row returns the top unsorted.\n",
    "        ranked_iidx = get_elements(top_iidx, np.argsort(get_elements(recommendation.scores, top_iidx))[:, ::-1])\n",
    "        rank_scores = get_elements(recommendation.scores, ranked_iidx)\n",
    "\n",
    "        # Tenemos en cuenta los relevantes de los scores (ya ordenados top cutoff)\n",
    "        mask_threshold=(rank_scores>self.threshold)\n",
    "        # Ordenamos test para que concuerde uid y iid con el orden de rank_scores (top cutoff)\n",
    "        mask_test=np.take_along_axis(self.test.matrix(),ranked_iidx, axis=1)\n",
    "        # Tenemos en cuenta los relevantes del test\n",
    "        mask_test=(mask_test>self.threshold)\n",
    "        \n",
    "        \"\"\"\n",
    "        print(rank_scores)\n",
    "        print(mask_threshold)\n",
    "        print(mask_test)\n",
    "        \"\"\"\n",
    "        \n",
    "        scores=mask_threshold*mask_test\n",
    "        \n",
    "        # Cálculos para precisión\n",
    "        pk=np.sum(scores, axis=1)/self.cutoff\n",
    "        # Por último promediamos la precisión con el número de usuarios\n",
    "        result=np.sum(pk)/len(pk)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "class Recall(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(test, cutoff)\n",
    "        # Código aquí...\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        # Código aquí...\n",
    "        # Nos quedamos con los TOP cutoff\n",
    "        top_iidx = top_positions_per_row(recommendation.scores, self.cutoff)\n",
    "        # Sort because top_positions_per_row returns the top unsorted.\n",
    "        ranked_iidx = get_elements(top_iidx, np.argsort(get_elements(recommendation.scores, top_iidx))[:, ::-1])\n",
    "        rank_scores = get_elements(recommendation.scores, ranked_iidx)\n",
    "\n",
    "        # Tenemos en cuenta los relevantes de los scores (ya ordenados top cutoff)\n",
    "        mask_threshold=(rank_scores>self.threshold)\n",
    "        # Ordenamos test para que concuerde uid y iid con el orden de rank_scores (top cutoff)\n",
    "        mask_test=np.take_along_axis(self.test.matrix(),ranked_iidx, axis=1)\n",
    "        # Tenemos en cuenta los relevantes del test\n",
    "        mask_test=(mask_test>self.threshold)\n",
    "        \"\"\"\n",
    "        print(recommendation.ranked_iidx)\n",
    "        print(mask_cutoff)\n",
    "        print(mask_test)\n",
    "        print(self.test.matrix())\n",
    "        \"\"\"\n",
    "    \n",
    "        scores=mask_threshold*mask_test\n",
    "        \n",
    "        \n",
    "        # Cálculos para recall\n",
    "        # Relevantes por usuario\n",
    "        # Relevantes totales test\n",
    "        relevante_total_test=(self.test.matrix()>self.threshold)\n",
    "        relevantes=np.sum(relevante_total_test,axis=1)\n",
    "        # Para solucionar divisiones por cero cuando no hay resultados relevantes para un usuario\n",
    "        relevantes[relevantes == 0]=1\n",
    "        # Para calcular recall de cada usuario dividimos\n",
    "        # número de relevantes TOP cutoff entre número de relevantes totales\n",
    "        pk=np.sum(scores, axis=1)/relevantes\n",
    "        # Por último promediamos el recall con el número de usuarios\n",
    "        result=np.sum(pk)/len(pk)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJDzjUp-hwNZ",
    "tags": []
   },
   "source": [
    "### Ejercicio 3 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)\n",
    "\n",
    "Ejemplo de tabla de resumen:\n",
    "\n",
    "||Precision@K|Recall@K|Tiempo de ejecución\n",
    "|-|:-:|:-:|:-:\n",
    "|Algoritmo 1|...|...|...\n",
    "|Algoritmo 2|...|...|...\n",
    "|...|...|...|...\n",
    "|Algoritmo n|...|...|..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpXHr18Cdl2Q",
    "tags": []
   },
   "source": [
    "## Ejercicio 4: Ampliaciones (1pt)\n",
    "\n",
    "Elegir uno de los siguientes ejercicios:\n",
    "\n",
    "* Implementar dos variantes de kNN a elección del estudiante, por ejemplo: kNN normalizado, vecinos próximos orientado a item, similitud de Pearson, kNN centrado en la media. Indicación: para kNN normalizado el algoritmo exigirá un mínimo de ratings de vecinos para aceptar recomendar un item (con ello se mejora el acierto de la recomendación, de forma similar a la recomendación por rating promedio).\n",
    "* Implementar filtrado colaborativo mediante factorización de matrices.\n",
    "* Crear una implementación de las estructuras de ratings con matrices dispersas, de forma que sea posible generar recomendaciones sobre conjuntos de datos más grandes, tales como [MovieLens 10M](https://grouplens.org/datasets/movielens/10m) y [MovieLens 25M](https://grouplens.org/datasets/movielens/25m).\n",
    "\n",
    "Para probar las implementaciones deberá completarse la función `student_test()` para ilustrar la ejecución de las variantes adicionales, y se incluirán las filas que correspondan en la tabla del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "MOfT2yZGpMNi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Código aquí: clases, funciones...\n",
    "# kNN normalizado\n",
    "class UserKNNRecommenderNormalized(Recommender):\n",
    "    def __init__(self, training, sim, k, k_min):\n",
    "        super().__init__(training)\n",
    "        self.sim = sim\n",
    "        self.k = k\n",
    "\n",
    "        not_rated_mask = (training.matrix() == 0)\n",
    "\n",
    "        # Indices de los k usuarios mas similares a cada usuario\n",
    "        uidx = top_positions_per_row(sim.similarity_matrix(), k)\n",
    "        print(uidx.shape)\n",
    "        mask=np.zeros_like(training.matrix())\n",
    "        mask[uidx,np.arange(mask.shape[1])]=1\n",
    "       \n",
    "        print(\"Mask\")\n",
    "        print(mask)\n",
    "\n",
    "        # Mascara con 1s en las posiciones de los k usuarios mas similares a cada usuario\n",
    "        # y 0s en el resto\n",
    "        top_similar_mask = np.zeros_like(sim.similarity_matrix())\n",
    "        top_similar_mask[np.arange(top_similar_mask.shape[0]), uidx.T] = 1\n",
    "\n",
    "        # Matriz de similitudes entre los k usuarios mas similares a cada usuario.\n",
    "        # El resto es 0.\n",
    "        knn_sim = sim.similarity_matrix() * top_similar_mask\n",
    "        \n",
    "        ####\n",
    "        #mean_ratings = np.divide(sum_ratings, n_ratings, out=np.zeros_like(sum_ratings), where = (n_ratings!=0))\n",
    "\n",
    "        # Creamos un vector con la media de los ratings de cada item\n",
    "        # si tiene por lo menos minr ratings. Si tiene menos, la media es 0.\n",
    "        #mean_ratings = np.where(n_ratings >= k_min, mean_ratings, 0)\n",
    "        \n",
    "        # Norma de cada item\n",
    "        mask_scores=(training.matrix()!=0)\n",
    "        norms=knn_sim @ mask_scores\n",
    "        print(mask_scores)\n",
    "        print(sim.similarity_matrix())\n",
    "        print(norms)\n",
    "\n",
    "        # Creamos la matriz de scores donde cada score es la media ponderada (segun la similitud entre usuarios)\n",
    "        # de los ratings de los k usuarios mas similares\n",
    "        knn_scores=knn_sim @ training.matrix()\n",
    "        # Normalizamos\n",
    "        self.scores = np.divide(knn_scores, norms,out=np.zeros_like(knn_scores), where = (norms!=0))\n",
    "\n",
    "        # Nos quedamos solo con los scores de los items que no han sido valorados por cada usuario\n",
    "        self.scores = self.scores * not_rated_mask\n",
    "        \n",
    "        #self.scores = np.where(n_ratings >= minr, mean_ratings, 0)\n",
    "        \n",
    "class CosineItemSimilarity:\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "        ratings_matrix = training.matrix()\n",
    "\n",
    "        dots = ratings_matrix.T @ ratings_matrix\n",
    "        mods = np.sqrt(dots.diagonal())\n",
    "\n",
    "        # To avoid 0/0 later if some row is all zeros (and hence the row modulus is zero).\n",
    "        mods[mods==0] = 1\n",
    "\n",
    "        # Vamos ahora a dividir por los modulos\n",
    "        # Dividimos cada fila de dots por cada elemento de mods\n",
    "        # Es decir, primera fila de mods por primer elemento de mods,...\n",
    "        self.sim = dots/mods[:, None]\n",
    "\n",
    "        # Dividimos cada columna de sim por cada elemento de mods.\n",
    "        # Es decir, primera columna de sim por primer elemento de mods,...\n",
    "        self.sim = self.sim/mods\n",
    "\n",
    "        # Ponemos a 0 la diagonal porque no queremos que un item sea similar a si mismo\n",
    "        np.fill_diagonal(self.sim,0)\n",
    "\n",
    "    def similarity_matrix(self):\n",
    "        return self.sim\n",
    "\n",
    "class ItemKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k):\n",
    "        super().__init__(training)\n",
    "        self.sim = sim\n",
    "        self.k = k\n",
    "\n",
    "        not_rated_mask = (training.matrix() == 0)\n",
    "\n",
    "        # Indices de los k usuarios mas similares a cada usuario\n",
    "        iidx = top_positions_per_row(sim.similarity_matrix(), k)\n",
    "\n",
    "        # Mascara con 1s en las posiciones de los k usuarios mas similares a cada usuario\n",
    "        # y 0s en el resto\n",
    "        top_similar_mask = np.zeros_like(sim.similarity_matrix())\n",
    "        top_similar_mask[np.arange(top_similar_mask.shape[0]), iidx.T] = 1\n",
    "\n",
    "        # Matriz de similitudes entre los k usuarios mas similares a cada usuario.\n",
    "        # El resto es 0.\n",
    "        knn_sim = sim.similarity_matrix() * top_similar_mask\n",
    "\n",
    "        # Creamos la matriz de scores donde cada score es la media ponderada (segun la similitud entre usuarios)\n",
    "        # de los ratings de los k usuarios mas similares\n",
    "        self.scores = knn_sim @ training.matrix()\n",
    "\n",
    "        # Nos quedamos solo con los scores de los items que no han sido valorados por cada usuario\n",
    "        self.scores = self.scores * not_rated_mask\n",
    "        \n",
    "\n",
    "def student_test():\n",
    "    # Código de prueba aquí...\n",
    "    ratings = Ratings('recsys-data/toy1.csv')\n",
    "    train, test = ratings.random_split(0.3)\n",
    "    sim = CosineUserSimilarity(train)\n",
    "    k=4\n",
    "    knn = UserKNNRecommenderNormalized(train, sim, k,2)\n",
    "    recommendation = knn.recommend(3)\n",
    "    display(recommendation._recommendation)\n",
    "    print(recommendation.display(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (4,4) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17080/1296437426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstudent_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17080/1280654788.py\u001b[0m in \u001b[0;36mstudent_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCosineUserSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUserKNNRecommenderNormalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mrecommendation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommendation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recommendation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17080/1280654788.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, training, sim, k, k_min)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muidx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muidx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (4,4) (5,) "
     ]
    }
   ],
   "source": [
    "student_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucORmwfCh4Um",
    "tags": []
   },
   "source": [
    "### Ejercicio 4 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /home/xu/.local/lib/python3.8/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install termcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda de prueba\n",
    "\n",
    "Descarga los ficheros de datos y coloca sus contenidos en una carpeta **recsys-data** en el mismo directorio que este *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Testing toy 1 dataset\n",
      "\u001b[34mReading the data at 11:06:36...\u001b[0m\n",
      "Ratings matrix takes 0.0 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "11 ratings by 4 users on 5 items\n",
      "Ratings of user v: {'b': 4.0, 'c': 5.0, 'd': 3.0}\n",
      "Ratings of item b: {'v': 4.0, 'x': 2.0, 'y': 4.0}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:0.9786 b:0.7992 d:0.7805 c:0.4615>\n",
      "    User x -> <c:0.9447 a:0.6399 d:0.5218 e:0.4147>\n",
      "    User y -> <b:0.7742 d:0.5684 c:0.4562 a:0.2646>\n",
      "    User z -> <d:0.9437 e:0.6818 a:0.6176 c:0.6169>\n",
      "Precision@4 = 0.0\n",
      "Recall@4 = 0.0\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing MajorityRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <b:2 c:2 d:1 e:1>\n",
      "    User x -> <b:2 c:2 d:1 e:1>\n",
      "    User y -> <b:2 c:2 d:1 e:1>\n",
      "    User z -> <b:2 c:2 d:1 e:1>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing AverageRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:3>\n",
      "    User x -> <c:4.5 d:4>\n",
      "    User y -> <d:4>\n",
      "    User z -> <c:4.5 b:3.3333 a:3>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Testing UserKNNRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:1.7295 e:0.6746>\n",
      "    User x -> <c:2.1927 d:0.506>\n",
      "    User y -> <d:2.6588 e:1.3494>\n",
      "    User z -> <c:2.1213 b:1.6971>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "=========================\n",
      "Testing toy 2 dataset\n",
      "\u001b[34mReading the data at 11:06:36...\u001b[0m\n",
      "Ratings matrix takes 0.0 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "22 ratings by 5 users on 10 items\n",
      "Ratings of user 1: {1: 1.0, 5: 5.0, 7: 2.0, 10: 5.0}\n",
      "Ratings of item 2: {2: 2.0, 4: 2.0}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <9:0.8289 4:0.7163 2:0.6674 7:0.5865>\n",
      "    User 2 -> <4:0.9622 10:0.9527 3:0.7352 1:0.6778>\n",
      "    User 3 -> <9:0.8817 7:0.8811 2:0.8464 5:0.8138>\n",
      "    User 4 -> <3:0.9561 1:0.7253 9:0.6602 4:0.644>\n",
      "Precision@4 = 0.0\n",
      "Recall@4 = 0.0\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing MajorityRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <5:2 3:1 4:1 6:1>\n",
      "    User 2 -> <5:2 3:1 4:1 6:1>\n",
      "    User 3 -> <5:2 3:1 4:1 6:1>\n",
      "    User 4 -> <5:2 3:1 4:1 6:1>\n",
      "Precision@4 = 0.0\n",
      "Recall@4 = 0.0\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing AverageRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <4:4 6:4 9:2.5 2:2>\n",
      "    User 2 -> <5:4 10:3.3333 1:2.6667>\n",
      "    User 3 -> <4:4 6:4 7:2.6667 9:2.5>\n",
      "    User 4 -> <5:4 6:4 1:2.6667 9:2.5>\n",
      "Precision@4 = 0.0\n",
      "Recall@4 = 0.0\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Testing UserKNNRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <4:2.2382 6:1.9852 9:1.3157 3:1.121>\n",
      "    User 2 -> <10:2.4731 5:1.9231 8:1.5 3:1.2667>\n",
      "    User 3 -> <6:2.3094 3:1.8475 9:1.8475 7:1.6725>\n",
      "    User 4 -> <5:2.2317 6:1.5 1:0.9082 9:0.5>\n",
      "Precision@4 = 0.0\n",
      "Recall@4 = 0.0\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "=========================\n",
      "Testing MovieLens '1 million' dataset\n",
      "\u001b[34mReading the data at 11:06:36...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8400/2459295587.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  self.ratings_df=pd.read_csv(filepath_or_buffer=file, sep = sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings matrix takes 170.8 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:09 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "1,000,209 ratings by 6,040 users on 3,706 items\n",
      "Ratings of user 200: {8: 3.0, 170: 5.0, 940: 4.0, 1059: 5.0, 1127: 4.0, 1441: 4.0, 1605: 1.0, 1911: 2.0, 2041: 5.0, 2355: 3.0, 2555: 2.0, 2572: 5.0, 2599: 3.0, 2605: 2.0, 2683: 3.0, 2694: 5.0, 2699: 4.0, 2706: 2.0, 2759: 2.0, 2770: 2.0, 2779: 2.0, 2827: 3.0, 2997: 4.0, 3051: 5.0, 3408: 5.0, 3751: 4.0}\n",
      "Ratings of item 1000: {474: 5.0, 1733: 2.0, 2820: 3.0, 3032: 4.0, 3193: 2.0, 3197: 3.0, 3224: 4.0, 3391: 3.0, 3507: 4.0, 3526: 3.0, 3644: 5.0, 3829: 4.0, 3868: 4.0, 3942: 1.0, 4088: 3.0, 4139: 4.0, 4732: 3.0, 5426: 2.0, 5682: 1.0, 5916: 1.0}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <3786:0.9996 3167:0.9991 136:0.999 1279:0.999 2558:0.9989 230:0.9988 1063:0.9987 2908:0.9987 313:0.9986 2643:0.9985>\n",
      "    User 2 -> <2577:1 347:0.9995 3402:0.9994 2006:0.9986 1759:0.9984 1624:0.9984 3385:0.9984 3247:0.9983 89:0.9981 624:0.9974>\n",
      "    User 3 -> <1009:0.9999 3944:0.9997 3745:0.9996 441:0.999 2799:0.9988 3730:0.9985 3390:0.9984 309:0.9982 1664:0.998 3859:0.9978>\n",
      "    User 4 -> <2918:0.9997 3524:0.9996 2493:0.9996 2459:0.9993 1417:0.9992 729:0.9989 1858:0.9986 3372:0.998 1856:0.9974 1579:0.9974>\n",
      "Precision@10 = 0.0\n",
      "Recall@10 = 0.0\n",
      "\u001b[34m--> elapsed time: 0:00:02 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing MajorityRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <2858:2276 260:2092 1196:2003 2028:1828 1198:1792 593:1786 2762:1737 2571:1721 1210:1715 608:1682>\n",
      "    User 2 -> <2858:2276 260:2092 1196:2003 2028:1828 1198:1792 593:1786 2762:1737 2571:1721 1210:1715 608:1682>\n",
      "    User 3 -> <2858:2276 260:2092 1196:2003 2028:1828 1198:1792 593:1786 2762:1737 2571:1721 1210:1715 608:1682>\n",
      "    User 4 -> <2858:2276 260:2092 1196:2003 2028:1828 1198:1792 593:1786 2762:1737 2571:1721 1210:1715 608:1682>\n",
      "Precision@10 = 0.04806291390728477\n",
      "Recall@10 = 0.08411113023036038\n",
      "\u001b[34m--> elapsed time: 0:00:01 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing AverageRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <3245:4.8 53:4.7143 1423:4.6667 2905:4.6271 2019:4.5667 318:4.5567 858:4.5474 50:4.5171 922:4.5066 1148:4.5007>\n",
      "    User 2 -> <3245:4.8 53:4.7143 1423:4.6667 2905:4.6271 2019:4.5667 858:4.5474 745:4.5322 50:4.5171 922:4.5066 527:4.5011>\n",
      "    User 3 -> <3245:4.8 53:4.7143 1423:4.6667 2905:4.6271 2019:4.5667 318:4.5567 858:4.5474 745:4.5322 50:4.5171 922:4.5066>\n",
      "    User 4 -> <3245:4.8 53:4.7143 1423:4.6667 2905:4.6271 2019:4.5667 318:4.5567 858:4.5474 745:4.5322 50:4.5171 922:4.5066>\n",
      "Precision@10 = 0.02231788079470199\n",
      "Recall@10 = 0.03072456163987147\n",
      "\u001b[34m--> elapsed time: 0:00:01 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:06 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:11 <--\u001b[0m\n",
      "Testing UserKNNRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <2080:7.762 595:7.7555 2078:7.5221 1028:7.3707 2081:7.3664 593:7.1862 539:6.7149 2396:6.4063 2096:6.4045 356:6.2173>\n",
      "    User 2 -> <1580:10.2388 260:9.3034 1608:8.9713 1961:8.7534 733:8.3107 316:8.208 527:8.1247 2763:8.0284 1240:7.7006 858:7.5351>\n",
      "    User 3 -> <2571:9.9567 1198:8.4205 2987:7.6296 457:7.2453 1214:6.6526 1240:6.4791 110:6.1196 1127:6.0289 648:5.8921 1356:5.7916>\n",
      "    User 4 -> <260:16.4481 2947:11.4749 110:11.3471 858:11.0612 1221:9.9354 1610:8.8879 1953:8.7876 457:8.7428 589:8.3949 1222:8.2185>\n",
      "Precision@10 = 0.12543046357615895\n",
      "Recall@10 = 0.2046534838065658\n",
      "\u001b[34m--> elapsed time: 0:00:01 <--\u001b[0m\n",
      "=========================\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "# Test data structures and algorithms on a dataset.\n",
    "def test(ratings_file, example_user, example_item, k, minr, topn=np.inf, cutoff=np.inf, threshold=1, sep=','):\n",
    "    print(colored(f'Reading the data at ' + time.strftime('%X...'), 'blue'))\n",
    "    start = time.time()\n",
    "    ratings = Ratings(ratings_file, sep)\n",
    "    print(f'Ratings matrix takes {round(10 * ratings.matrix().nbytes / 1024 / 1024) / 10:,} MB in RAM')\n",
    "    timer(start)\n",
    "\n",
    "    # Test Ratings class on the dataset.\n",
    "    test_data(ratings, example_user, example_item)\n",
    "    \n",
    "    # Produce a rating split and test a set of recommenders. \n",
    "    train, test = ratings.random_split(0.8)\n",
    "    metrics = [Precision(test, cutoff=cutoff, threshold=threshold), Recall(test, cutoff=cutoff, threshold=threshold)]\n",
    "    run_recommenders(train, metrics, k, minr, topn)\n",
    "\n",
    "# Test the rating data handling code (Ratings class).\n",
    "def test_data(ratings, example_user, example_item):\n",
    "    print('-------------------------\\nTesting the ratings data structures')\n",
    "    print(f'{ratings.nratings():,} ratings by {ratings.nusers():,} users on {ratings.nitems():,} items')\n",
    "    print(f'Ratings of user {example_user}: {ratings.user_ratings(example_user)}')\n",
    "    print(f'Ratings of item {example_item}: {ratings.item_ratings(example_item)}')\n",
    "\n",
    "# Run some recommenders on the some rating data as input - no evaluation.\n",
    "def run_recommenders(train, metrics, k, minr, topn):\n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    run_recommender(RandomRecommender(train), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(MajorityRecommender(train, threshold=4), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(AverageRecommender(train, minr), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('Creating user cosine similarity')\n",
    "    sim = CosineUserSimilarity(train)\n",
    "    start = timer(start)\n",
    "    # print('-------------------------')\n",
    "    print('Creating kNN recommender')\n",
    "    knn = UserKNNRecommender(train, sim, k)\n",
    "    start = timer(start)\n",
    "    run_recommender(knn, metrics, topn)\n",
    "    timer(start)\n",
    "    \n",
    "    # print('-------------------------')\n",
    "    # start = time.time()\n",
    "    # print('Creating MF recommender')\n",
    "    # mf = MF(train, dim=20, lrate=.0001, reg=.005, nepochs=50)\n",
    "    # timer(start)\n",
    "    # start = time.time()\n",
    "    # run_recommender(mf, metrics, topn)\n",
    "    # timer(start)\n",
    "\n",
    "# Run a recommender and evaluate a list of metrics on its output.\n",
    "def run_recommender(recommender, metrics, topn):\n",
    "    print(f'Testing {recommender} (top {topn})')\n",
    "    recommendation = recommender.recommend(topn)\n",
    "    print('Four example recommendations:\\n' + recommendation.display(4))\n",
    "    for metric in metrics:\n",
    "        print(metric, '=', metric.compute(recommendation))\n",
    "\n",
    "from termcolor import colored\n",
    "def timer(start):\n",
    "    print(colored(f'--> elapsed time: {datetime.timedelta(seconds=round(time.time() - start))} <--', 'blue'))\n",
    "    return time.time()\n",
    "    \n",
    "np.random.seed(0)\n",
    "print('=========================\\nTesting toy 1 dataset')\n",
    "test('recsys-data/toy1.csv', example_user='v', example_item='b', k=4, minr=2, topn=4, cutoff=4)\n",
    "print('=========================\\nTesting toy 2 dataset')\n",
    "test('recsys-data/toy2.csv', example_user=1, example_item=2, k=4, minr=2, topn=4, cutoff=4)\n",
    "print('=========================\\nTesting MovieLens \\'1 million\\' dataset')\n",
    "test('recsys-data/ratings-1m.dat', example_user=200, example_item=1000, k=10, minr=3, topn=10, cutoff=10, threshold=4, sep='::')\n",
    "print('=========================\\nDone.')\n",
    "\n",
    "# Additional testing?\n",
    "#student_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salida obtenida por el estudiante\n",
    "\n",
    "*(por hacer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado P2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
